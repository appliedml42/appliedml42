
<p align="center"><b>Please reach out if you would like to consult on your AI/ML project.</b></p>

<p align="center">
<img width="454" alt="Screenshot 2022-12-03 at 8 10 52 PM" src="https://user-images.githubusercontent.com/88844341/205474021-a1bae1a2-5570-4d31-a996-867945f692f4.png">
</p>

<p align="center">
  <a href="https://www.linkedin.com/in/abhishekpatnia/">
    <img src="https://img.shields.io/badge/linkedin-%230077B5.svg?&style=for-the-badge&logo=linkedin&logoColor=white" />
  </a>&nbsp;&nbsp;
  <a href="https://twitter.com/appliedml42">
    <img src="https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white" />
  </a>&nbsp;&nbsp;
  <a href="mailto:appliedml42@gmail.com">
    <img src="https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=gmail&logoColor=white" />
  </a>
</p>

I have been using Machine Learning, Deep Learning, and Natural Language Processing to bring value to organizations like Amazon and Tinder since 2011. Andrew Ng's lecture at Amazon introduced me to Deep Learning in the early 2010s. I have been hooked ever since.  

# Experience

<details><summary>2019-Preset</summary>

## Staff MLE & Technical Lead, Tinde
Technical Lead for a Machine Learning Engineers & Risk Analysts team. I started the group and grew it to 9 people. This team owns detection models/algorithms for identifying Trust & Safety violations.
+ Responsible for hiring, mentoring, and team charter.
+ Organized Risk Analysts under the Escalations and Early Warning team. Collaborated with the team to invent KPIs for the org. This team optimizes detection strategies using existing signals and provides feedback highlighting detection gaps.
+ Removed data scarcity by establishing best practices for leveraging moderation logs for training and evaluation datasets.
+ Established modeling best practices. Transformers for text classification by pre-training on Tinderâ€™s unique data; Text pre-processing pipelines to handle adversarial attacks; Metadata embeddings to improve multi-lingual performance; ConvNeXT family of models for effective and efficient image classifiers.
+ Enabled real-time model inference. TFLite and Quantization for CPU-based models; TensorRT and Triton for GPU-based models; Collaborated with Infra team to establish requirements for the K8-based model endpoint framework.
</details>

<details><summary>2015-2019</summary>

## Senior Applied Scientist, Amazon
Technical lead for the query understanding science team.
+ Led the Research & Development of the first query -> shopping intent Recurrent Neural Network model. This model became the foundation for multiple shopping experiences that required mapping of queries to shopping intents.
+ Established best practices for training Deep Learning models and their deployment for the team. Built GPU-based training and batch-inference infrastructure over AWS Batch.
+ Collaborated closely with the infrastructure team to establish requirements for the inference framework. Made sure the team invested in a Python-based framework to make model deployments painless.
</details>

<details><summary>2011-2015</summary>

## Senior Software Development Engineer
Founding engineer on the [X-Ray](https://www.youtube.com/watch?v=AbzOLua2baw) team. X-Ray identifies a bookâ€™s topics, characters, images, and essential passages.
+ Developed algorithms to identify characters and all their mentions in a book. For example, the algorithm will ensure that Mr. Potter and Harry Potter are associated with the same character Harry Potter. 
+ Led the Book Maps teams and developed algorithms to identify images and critical passages in a book.
+ Developed testing at scale methodologies to go code complete months before the deadline. Concretely, each new algorithm change was tested against thousands of books, and the most common bugs were sorted by frequency and prioritized.
+ Generated n-gram count statistics across the whole Kindle catalog using Map-Reduce and Dynamo DB. This data is used for topic modeling. 
+ Developed the Kindle N-gram Corpus. N-gram frequency table using Map-Reduce and DynamodDB across all Kindle books circa 2012. Essential topics in books are identified using this dataset.
</details>

<details><summary>Patents & Publications</summary>
  
+ Text Classifiers for Small Scale Relevance
+ [Digital Content excerpt Identification](https://patents.google.com/patent/US9910916B1/en)
+ [Identifying entities in a digital work](https://patents.google.com/patent/US9639518B1/en)
+ [Identifying topics in a digital work](https://patents.google.com/patent/US9613003B1/en)
+ [Visual representation of supplemental information for a digital work â€¢ Providing supplemental information for a digital work](https://patents.google.com/patent/US20130080881A1/en)
+ [Providing supplemental information for a digital work](https://patents.google.com/patent/US8842085B1/en)
+ [Presenting content in multiple languages](https://patents.google.com/patent/US9684641B1/en)
+ [Providing supplemental information for a digital work in a user interface](https://patents.google.com/patent/US9128581B1/en)
+ [Navigating supplemental information for a digital work](https://patents.google.com/patent/US9471547B1/en)
+ [Display screen having a graphical user interface for providing supplemental information of a digital work](https://patents.google.com/patent/USD674810S1/en)
+ [Layout-aware text extraction from full-text PDF of scientific articles](https://scfbm.biomedcentral.com/articles/10.1186/1751-0473-7-7)
</details>

<p align="center"><b>Technologies & Tools</b></p>

[<img src="https://img.shields.io/badge/PyTorch-Primary Modeling Framework-important.svg?logo=PyTorch">](https://pytorch.org)
[<img src="https://img.shields.io/badge/PyTorch Lightning-Primary Modeling Framework-important.svg?logo=PyTorch Lightning">](https://www.pytorchlightning.ai)
[<img src="https://img.shields.io/badge/SQLite-On Disk Random IO-important.svg?logo=SQLite">](https://www.sqlite.org/index.html)
[<img src="https://img.shields.io/badge/TensorRT-GPU Inference-important.svg?logo=NVIDIA">](https://developer.nvidia.com/tensorrt)
[<img src="https://img.shields.io/badge/Triton-GPU Inference-important.svg?logo=NVIDIA">](https://developer.nvidia.com/nvidia-triton-inference-server)
[<img src="https://img.shields.io/badge/Python-Primary Language-important.svg?logo=Python">](https://www.python.org)
[<img src="https://img.shields.io/badge/NumPy--important.svg?logo=NumPy">](https://numpy.org)
[<img src="https://img.shields.io/badge/Jupyter-Primary IDE-important.svg?logo=Jupyter">](https://jupyter.org)
[<img src="https://img.shields.io/badge/PyCharm-Primary IDE-important.svg?logo=PyCharm">](https://www.jetbrains.com/pycharm/)
[<img src="https://img.shields.io/badge/PySpark-Primary Analytics-important.svg?logo=Apache Spark">](https://spark.apache.org/docs/latest/api/python/)
[<img src="https://img.shields.io/badge/Databricks-End User Experience-important.svg?logo=Databricks">](https://www.databricks.com)
[<img src="https://img.shields.io/badge/Docker-Working Knowledge-important.svg?logo=Docker">](https://www.docker.com)
[<img src="https://img.shields.io/badge/AWS-Working Knowledge-important.svg?logo=Amazon AWS">](https://aws.amazon.com)
[<img src="https://img.shields.io/badge/K8s-Working Knowledge-important.svg?logo=Kubernetes">](https://kubernetes.io)
[<img src="https://img.shields.io/badge/MLonGPUs-Interface Using Python-important.svg?logo=Nvidia">](https://www.nvidia.com/en-us/ai-data-science/)
[<img src="https://img.shields.io/badge/TensorFlow-Secondary Modeling Framework-important.svg?logo=TensorFlow">](https://www.tensorflow.org)
[<img src="https://img.shields.io/badge/Keras-Secondary Modeling Framework-important.svg?logo=Keras">](https://keras.io)
[<img src="https://img.shields.io/badge/TFLite-CPU Inference-important.svg?logo=TensorFlow">](https://www.tensorflow.org/lite)




# Notes
- [Pytorch Map-style Dataset for 800+GB Text Data, 2022](https://wandb.ai/appliedml42/language_modeling/reports/Pytorch-Map-style-Dataset-for-800-GB-Text-Data--VmlldzoyMDk3NDgx)
- [Optimized Theano & Keras on AWS Lambda, 2017](https://becominghuman.ai/running-deep-learning-models-on-aws-lambda-cfd2f76ca048)

# Personal Projects ðŸ“š
## 2023
Details coming soon! But, high level I want to achieve 3 goals this year.
* Build a AI powered Discord server to keep up with AI publications. 
* Revisit Language Models with Pytorch 2.0 and train the most efficient 1.2B parameter model possible. Explore inference on this model using TensorRT & Triton.
* Continue Diffusion Models Exploration.
## 2022
<details><summary>Billion Scale Language Models</summary>
  
Billion-scale language models like GPT-2 and GPT-3 and their derivatives have become essential models for accomplishing traditional NLP tasks like classifications. At the same time, they have opened the door to possibilities like code generation. Understanding and training these models require a deep understanding of Transformers and how to train them across multiple GPUs on billions of tokens. In these experiments, I am learning how to train billion parameter models on multiple GPUs on billions of tokens. For more details, go to this [repository](https://github.com/appliedml42/language-modeling). 
</details>

<details><summary>Stable Diffusion</summary>

Stable Diffusion is revolutionizing the Generative AI field. New text-to-image models like DreamBooth are making art accessible to many more people. My personal experience is in Natural Language Processing; however, lucky for me, FastAI just released a new course on Stable Diffusion. I am excited to learn and follow alongâ€”more details in this [repository](https://github.com/appliedml42/fastai-stable-diffusion). 
</details>
